# Data Science in Production

# Introduction

This is a project that shows my progress in Data Science training in production. 

Data Science in Prodution is a course taught by data scientist **Meigarom Lopes**. It teaches how to build a data science project using an easy-to-understand methodology. And in the end, he teaches how to deploy the model in production.

The challange of this project is to make a sales prevision of **Rossmann's Store**. Therefore, it's used the datasets from *Kaggle*.

This project is divided into 10 modules where the necessary steps to make a complete data science project are presented. They are:

- Understanding the Bussiness Problem

- Data Description

- Featuring Engineering

- Exploratory Data Analysis (EDA)

- Data Preparation

- Feature Selection

- Machine Learning Modeling

- Hyperparameter Fine Tuning

- Error Translation and Interpretation 

- Deploy Model to Production

# Module 01 - Understanding the business problem

In this module, I learn how important it is to understand the business problem before starting a data science project.

In the case of Rossmann's Stores the business problem was to make **a sales prevision of all the stores in the next six weeks**.

So, there are four importants points to consider:

- Understand the motivation of the problem - What is the motivation for making this a sales prevision ?

- Understand the root cause of the problem - Why do it ?

- Identify the project sponsor - Who's the stalkerholder ?

- Understand the solution format - Granulality, for example.

Using these points above, it was answered

- The CFO requested this solution during a monthly results meeting.

- The CFO wants to know the bugdet of each store to make reforms.

- The project sponsor is the CFO.

- The format solution is to make the predict of daily sales of each store in the next six weeks using predict methods.

# Module 02 - Data Description

In this module, I start getting familiar with the dataset to understand how complex is the problem that I have to solve.

With this, I analyse some features of the data set as:

- Dataset size
  -- Do I have the correct resources to work with ?
  -- Does the infrastrutucture support the amount of data ?
  





